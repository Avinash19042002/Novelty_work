{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbSNuCk5ARZa",
        "outputId": "1a3c2828-7752-4ce3-8ef1-acec9478ea1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf version: 2.13.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import seaborn as sns\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "print(\"tf version:\", tf.__version__)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLjRK7P6Acfp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "img = load_img('../germany_dataset/train/35/00035_00032_00000.png')\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUF9ig3EAgf0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "img = load_img('../germany_dataset/meta/37.png')\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DDJ9WqdAgRi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "img = load_img('../germany_dataset/test/01301.png')\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0Ch-kRMAgOC"
      },
      "outputs": [],
      "source": [
        "df_meta=pd.read_csv('../germany_dataset/Meta.csv')\n",
        "df_meta.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_bNFNykAgLl"
      },
      "outputs": [],
      "source": [
        "df_train=pd.read_csv('../germany_dataset/train.csv')\n",
        "num_of_classes = df_train[\"ClassId\"].nunique()\n",
        "df_train.head(), df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txV2GU3MAgJA"
      },
      "outputs": [],
      "source": [
        "df_test=pd.read_csv('../germany_dataset/test.csv')\n",
        "df_test.head(), df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0CSX1OyAgGl"
      },
      "outputs": [],
      "source": [
        "df_train=df_train[['ClassId','Path']]\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzcYP9fBAf7r"
      },
      "outputs": [],
      "source": [
        "path='../germany_dataset/'\n",
        "df_unique = df_train.copy().drop_duplicates(subset=[\"ClassId\"]).reset_index()\n",
        "\n",
        "# Display some pictures of the dataset\n",
        "fig, axes = plt.subplots(nrows=6, ncols=6, figsize=(8, 7),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(path + str(df_unique.Path[i])))\n",
        "    ax.set_title(df_unique.ClassId[i], fontsize = 12)\n",
        "plt.tight_layout(pad=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL3hSh80AfjA"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "path='../germany_dataset/'\n",
        "def img_preprocess(df_input):\n",
        "    X = []\n",
        "    for img_path in df_input:\n",
        "        img = cv2.imread(path + str(img_path))\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"Image cannot be loaded: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        img = cv2.resize(img, (30, 30))\n",
        "\n",
        "        img = img / 255.0\n",
        "\n",
        "        X.append(img)\n",
        "    X = np.array(X)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_-hylj8A2ib"
      },
      "outputs": [],
      "source": [
        "X=img_preprocess(df_train['Path'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9mduLMXA2VG"
      },
      "outputs": [],
      "source": [
        "y=df_train['ClassId'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRDptY5NA2GF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.20,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vrxKpiQA7-a"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsQrpgY6A77M"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Conv2D, InputLayer, Reshape, MaxPooling2D, Flatten,Dropout, BatchNormalization\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta5POd8UA74s"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(30, 30, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWU3XzKuBGS7"
      },
      "outputs": [],
      "source": [
        "starting_time = time.time()\n",
        "history=model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1000,verbose=1)\n",
        "\n",
        "ending_time = time.time()\n",
        "total_time = ending_time - starting_time\n",
        "total_time/=60\n",
        "\n",
        "print(\"Time taken fit : \",total_time,\" min\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__TLt7bhA72E"
      },
      "outputs": [],
      "source": [
        "df_test[\"ClassId\"] =df_test[\"ClassId\"].astype(int)\n",
        "print(\"Number of Test Images are \", len(df_test))\n",
        "df_test.dropna()\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM9V78cRA7qv"
      },
      "outputs": [],
      "source": [
        "X_test = img_preprocess(df_test[\"Path\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01I64V0mBNMW"
      },
      "outputs": [],
      "source": [
        "y_test = df_test[\"ClassId\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hhb3NkLBM8j"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwB4bkGwBMwu"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuoYBsWLBMhp"
      },
      "outputs": [],
      "source": [
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F44Qrx7BVXo"
      },
      "outputs": [],
      "source": [
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84_cXL6tBZLP"
      },
      "outputs": [],
      "source": [
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.sum(np.diag(confusion)) / np.sum(confusion)\n",
        "print(\"Total Accuracy: \", accuracy*100)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "classification_rep = classification_report(y_test, y_pred, labels=np.unique(y_pred))\n",
        "\n",
        "# Print the results\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion)\n",
        "\n",
        "\n",
        "lines = classification_rep.split('\\n')\n",
        "data = []\n",
        "\n",
        "for line in lines[2:-5]:  # Exclude header and footer lines\n",
        "    row_data = line.split()\n",
        "    if len(row_data) > 0:\n",
        "        class_name = row_data[0]\n",
        "        precision = float(row_data[1])\n",
        "        recall = float(row_data[2])\n",
        "        f1_score = float(row_data[3])\n",
        "        support = int(float(row_data[4]))\n",
        "        data.append([class_name, precision, recall, f1_score, support])\n",
        "\n",
        "# Create a DataFrame\n",
        "report = pd.DataFrame(data, columns=['Class', 'Precision', 'Recall', 'F1-Score', 'Support'])\n",
        "# Print the DataFrame\n",
        "print(\"\\n\\n\\n Summarizing the results : \")\n",
        "report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h1IcSqeBY-V"
      },
      "outputs": [],
      "source": [
        "class_names = []\n",
        "for i in range(num_of_classes):\n",
        "    class_names.append(\"Class \"+str(i))\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(confusion, annot=False, cmap=\"viridis\", xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}